1
00:00:00,000 --> 00:00:00,260

2
00:00:00,260 --> 00:00:03,800
Sharding and replication are
almost always done together.

3
00:00:03,800 --> 00:00:06,400
So, whenever you've got a
sharded environment-- and here

4
00:00:06,400 --> 00:00:11,510
I'm showing three shards, s0,
s1, and s2, and a mongos

5
00:00:11,510 --> 00:00:12,430
routing them--

6
00:00:12,430 --> 00:00:14,890
the shards themselves
are replica sets.

7
00:00:14,890 --> 00:00:16,250
And their replica sets
because otherwise

8
00:00:16,250 --> 00:00:17,840
they wouldn't be reliable.

9
00:00:17,840 --> 00:00:20,360
So, you just have to expect that
when you're dealing with

10
00:00:20,360 --> 00:00:22,810
a sharded environment, and best
practices dictate that

11
00:00:22,810 --> 00:00:24,790
that's the way you
would set it up.

12
00:00:24,790 --> 00:00:28,180
Next thing I wanted to point
out is that the mongos is

13
00:00:28,180 --> 00:00:30,300
doing what the driver was doing
before in the sense that

14
00:00:30,300 --> 00:00:34,130
the mongos is reconnecting to
members of the replica set.

15
00:00:34,130 --> 00:00:36,160
Because the mongos probably has
a connection all the way

16
00:00:36,160 --> 00:00:40,300
through to the primary node of
the replica set in each of

17
00:00:40,300 --> 00:00:43,950
these shards, and possibly
connections to the secondaries

18
00:00:43,950 --> 00:00:46,750
if it's allowing secondary
reads.

19
00:00:46,750 --> 00:00:50,190
So when there's failover within
a shard, it's the

20
00:00:50,190 --> 00:00:52,350
mongos that's going
to reconnect.

21
00:00:52,350 --> 00:00:55,340
And so the mongos has some
concept now of this seed list

22
00:00:55,340 --> 00:00:58,030
and knows which of these
nodes are part of it.

23
00:00:58,030 --> 00:01:00,980
The next thing that you should
realize is that there's still

24
00:01:00,980 --> 00:01:03,900
this concept of write concern,
and there's still the j value,

25
00:01:03,900 --> 00:01:07,470
and the w value, and the w
timeout, and those are going

26
00:01:07,470 --> 00:01:09,010
to be passed right through.

27
00:01:09,010 --> 00:01:12,890
So, if your application
specifies that it requires

28
00:01:12,890 --> 00:01:17,030
journaling to be true, let's
say, or w majority, a majority

29
00:01:17,030 --> 00:01:20,310
of nodes need to see the write
before it's completed, then

30
00:01:20,310 --> 00:01:23,030
your application's going to
specify that in the driver, or

31
00:01:23,030 --> 00:01:24,355
inside your application,
or next to

32
00:01:24,355 --> 00:01:26,540
your application drivers.

33
00:01:26,540 --> 00:01:28,360
And that's going to
go to the mongos.

34
00:01:28,360 --> 00:01:30,830
The mongos is going to route the
query to the appropriate

35
00:01:30,830 --> 00:01:34,700
shard in the replica set, and
then that j and that write

36
00:01:34,700 --> 00:01:38,100
concern are going to get
reflected in that final write.

37
00:01:38,100 --> 00:01:40,720
So you should continue to think
about having to specify

38
00:01:40,720 --> 00:01:43,600
those in the sense that it's a
replicated environment here

39
00:01:43,600 --> 00:01:45,310
and that those are
still meaningful.

40
00:01:45,310 --> 00:01:49,280
And they're going to apply
to each of the nodes.

41
00:01:49,280 --> 00:01:51,280
Now, so if you get a
multi-update, they've hit

42
00:01:51,280 --> 00:01:54,800
multiple nodes, then in each
node if you said I wanted the

43
00:01:54,800 --> 00:01:59,600
w value to be, let's say, 2
and j to be 1, then this

44
00:01:59,600 --> 00:02:01,900
mongos wouldn't get an

45
00:02:01,900 --> 00:02:03,640
acknowledgement for that write.

46
00:02:03,640 --> 00:02:06,720
It wouldn't complete it until
all the different nodes

47
00:02:06,720 --> 00:02:09,180
completed the write to a
majority of them and then it

48
00:02:09,180 --> 00:02:11,290
was committed to the journal
on the primary of each of

49
00:02:11,290 --> 00:02:13,000
these replica sets.

50
00:02:13,000 --> 00:02:15,930
Those are some things to keep
in mind as you're working in

51
00:02:15,930 --> 00:02:16,940
this environment.

52
00:02:16,940 --> 00:02:19,190
And the final point I'll make
is that usually mongos is

53
00:02:19,190 --> 00:02:21,770
replicated itself, so there's
probably a few of these

54
00:02:21,770 --> 00:02:22,810
hanging out here.

55
00:02:22,810 --> 00:02:26,010
Typically, you run them on the
same box as the application

56
00:02:26,010 --> 00:02:28,720
server itself, because they're
pretty lightweight.

57
00:02:28,720 --> 00:02:32,190
And the driver is just the way
they can take multiple names

58
00:02:32,190 --> 00:02:34,150
of hosts for a replica
set, they can

59
00:02:34,150 --> 00:02:35,740
take multiple mongos's.

60
00:02:35,740 --> 00:02:39,280
And if it can't, for some
reason, attach to a mongos or

61
00:02:39,280 --> 00:02:42,580
connect to a mongos, then it
will connect to another

62
00:02:42,580 --> 00:02:46,300
mongos, and the Python drivers
itself have classes just for

63
00:02:46,300 --> 00:02:48,010
dealing with shard environments,
so you can see

64
00:02:48,010 --> 00:02:49,790
them inside the driver docs.

65
00:02:49,790 --> 00:02:52,730
So that's what I want to point
out to you about sharding plus

66
00:02:52,730 --> 00:02:53,970
replication together.

67
00:02:53,970 --> 00:02:56,680
That you've got these replica
sets here, and you have these

68
00:02:56,680 --> 00:02:59,250
mongos's in front, and
everything you learned before

69
00:02:59,250 --> 00:03:03,350
about availability and
replication still applies, it

70
00:03:03,350 --> 00:03:06,270
just that it's passed through
to the various shard.

71
00:03:06,270 --> 00:03:08,090
All right, let's do a quiz.

72
00:03:08,090 --> 00:03:11,740
So, suppose you want to run
multiple mongos routers for

73
00:03:11,740 --> 00:03:12,340
redundancy.

74
00:03:12,340 --> 00:03:15,400
What level of the stack will
assure that you can failover

75
00:03:15,400 --> 00:03:17,810
to a different mongos from
within your application?

76
00:03:17,810 --> 00:03:21,260
Is it the mongod, mongos, the
drivers, or the sharding

77
00:03:21,260 --> 00:03:22,510
config servers?

78
00:03:22,510 --> 00:03:23,240