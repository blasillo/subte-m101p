1
00:00:00,000 --> 00:00:04,300
OK, bienvenidos a la semana 7
de MongoDB para desarrolladores.

2
00:00:04,300 --> 00:00:07,550
Esta semana vamos a hacer
algunas entrevistas a

3
00:00:07,550 --> 00:00:11,650
usuarios de MongoDB, y ahora
estoy aquí con Jon Hoffman de

4
00:00:11,650 --> 00:00:12,450
Foursquare.

5
00:00:12,450 --> 00:00:15,840
Ellos son uno de los primeros y más
grandes usuarios de MongoDB, así que

6
00:00:15,840 --> 00:00:17,150
gracias por venir aquí hoy Jon.

7
00:00:17,150 --> 00:00:19,170
Sí, gracias por invitarme.

8
00:00:19,170 --> 00:00:20,900
Vamos a hacer esto
muy casualmente.

9
00:00:20,900 --> 00:00:23,800
Tengo algunas preguntas que me
gustaría hacerte acerca del uso

10
00:00:23,800 --> 00:00:28,210
de MongoDB en Foursquare.

11
00:00:28,210 --> 00:00:31,180
Supongo que primero debemos hablar
acerca de lo que es Foursquare,

12
00:00:31,180 --> 00:00:32,890
porque alguno de nuestros estudiantes
internacionales podrían no estar

13
00:00:32,890 --> 00:00:34,822
familiarizados con él.

14
00:00:34,822 --> 00:00:37,200
¿Puedes decribirlo brevemente?

15
00:00:37,200 --> 00:00:38,880
Seguro, Foursquare es dos cosas.

16
00:00:38,880 --> 00:00:40,210
Es una utilidad social.

17
00:00:40,210 --> 00:00:42,720
Es una forma de decirle a tus
amigos dónde estas y saber

18
00:00:42,720 --> 00:00:45,380
ellos dónde están, y luego
también reutilizamos esa

19
00:00:45,380 --> 00:00:48,500
información y ayudamos en el
descubrimiento social de tu ciudad.

20
00:00:48,500 --> 00:00:52,990
Si estás buscando un nuevo
restaurante, o bar, o cualquier

21
00:00:52,990 --> 00:00:56,470
tipo de lugar en tu ciudad, puedes
usar la aplicación para buscar

22
00:00:56,470 --> 00:00:58,000
ese tipo de lugar,
y te daremos una

23
00:00:58,000 --> 00:01:01,230
recomendación basada en dónde
tus amigos han estado y

24
00:01:01,230 --> 00:01:03,570
dónde has estado antes.

25
00:01:03,570 --> 00:01:06,230
¿Y entonces éste es principalmente
una aplicación móvil?

26
00:01:06,230 --> 00:01:06,770
Sí.

27
00:01:06,770 --> 00:01:09,190
Así que lo usas en
tu teléfono--

28
00:01:09,190 --> 00:01:12,550
como tu iPhone, tu
BlackBerry o tu Android--

29
00:01:12,550 --> 00:01:16,400
y lo utilizas mientras
estás yendo hacia el lugar.

30
00:01:16,400 --> 00:01:18,510
¿Dame una idea para escalar esto?

31
00:01:18,510 --> 00:01:22,340
Como, ¿aproximadamente cuántos
"check-ins" ocurren y cuál es

32
00:01:22,340 --> 00:01:25,530
la frecuencia de los "check-ins"
y ese tipo de cosas?

33
00:01:25,530 --> 00:01:28,760
Los usuarios le permiten saber a
otros dónde están, o hacen "check-in"

34
00:01:28,760 --> 00:01:32,060
cerca de cinco millones
de veces por día.

35
00:01:32,060 --> 00:01:32,840
¡Vaya!

36
00:01:32,840 --> 00:01:34,110
Sí.

37
00:01:34,110 --> 00:01:36,360
Muy bien.

38
00:01:36,360 --> 00:01:42,580
¿Y cuál es el principal rol
de MongoDB en el sistema?

39
00:01:42,580 --> 00:01:44,830
MongoDB es nuestro principal
almacén de datos.

40
00:01:44,830 --> 00:01:46,350
Lo usamos para casi todo.

41
00:01:46,350 --> 00:01:49,070
Cada vez que alguien hace "check-in"--
todos esos 5 millones de "check-ins"

42
00:01:49,070 --> 00:01:51,210
todos los días son
almacenados en MongoDB.

43
00:01:51,210 --> 00:01:54,810
Almacenamos la información de
las cuentas de usuario en Mongo,

44
00:01:54,810 --> 00:01:58,660
almacenamos toda la información
asociada como información de

45
00:01:58,660 --> 00:02:02,090
lugares, consejos
que la gente deja--

46
00:02:02,090 --> 00:02:04,960
casi todo está
almacenado en Mongo.

47
00:02:04,960 --> 00:02:06,730
Qué genial.

48
00:02:06,730 --> 00:02:07,780
¿Cuál es tu rol ahí?

49
00:02:07,780 --> 00:02:09,360
Sólo para que la gente lo sepa.

50
00:02:09,360 --> 00:02:13,050
Administro el equipo de almacenamiento,
donde nos enfocamos en el

51
00:02:13,050 --> 00:02:14,210
almacenamiento "online" y "offline". 

52
00:02:14,210 --> 00:02:19,420
El almacenamiento "online" es
nuestra base de datos basada en Mongo.

53
00:02:19,420 --> 00:02:24,570
Bien, describe la evolución del
uso de MongoDB, desde el inicio

54
00:02:24,570 --> 00:02:28,300
y cómo ha evolucionado.

55
00:02:28,300 --> 00:02:30,020
¿Puedes decirnos cómo es eso?

56
00:02:30,020 --> 00:02:30,320
Claro.

57
00:02:30,320 --> 00:02:34,490
Foursquare inició en 2009,
y el prototipo para

58
00:02:34,490 --> 00:02:38,240
Foursquare fue en realidad
construido en base a MySQL.

59
00:02:38,240 --> 00:02:40,790
Y entonces ellos tuvieron que
reescribir cuando empezaron

60
00:02:40,790 --> 00:02:42,100
a tomar seriedad.

61
00:02:42,100 --> 00:02:46,680
Empezaron a reescribir la
aplicación en Scala y cambiamos

62
00:02:46,680 --> 00:02:49,990
de MySQL a Postgres.

63
00:02:49,990 --> 00:02:52,360
Eso estuvo bueno por un
rato, pero en algún momento

64
00:02:52,360 --> 00:02:55,640
nos dimos cuenta que necesitaríamos
distribuir nuestros datos en

65
00:02:55,640 --> 00:02:58,710
varios servidores.

66
00:02:58,710 --> 00:03:03,620
Y eso implicaría la eliminación
de muchas de las características

67
00:03:03,620 --> 00:03:08,360
que tienes en las bases de datos
relacionales, como las relaciones e

68
00:03:08,360 --> 00:03:12,230
integridad de transacciones, por lo
que tendríamos que movernos a algún

69
00:03:12,230 --> 00:03:15,540
otro tipo de sistema, ya sea SQL

70
00:03:15,540 --> 00:03:17,290
o algún otro.

71
00:03:17,290 --> 00:03:20,930
Así que buscamos algunas opciones,
y supimos de algunas personas que

72
00:03:20,930 --> 00:03:22,160
estaban usando Mongo.

73
00:03:22,160 --> 00:03:26,930
Empezamos a mover algunas
cosas a Mongo en el 2010.

74
00:03:26,930 --> 00:03:30,480
Y empezamos con sólo
unas pocas colecciones.

75
00:03:30,480 --> 00:03:33,400
Mudamos la base de datos
que almacena la información

76
00:03:33,400 --> 00:03:34,510
de lugares--

77
00:03:34,510 --> 00:03:37,980
información de lugares
como restaurantes y bares.

78
00:03:37,980 --> 00:03:41,982
Movimos eso a Mongo,
pero hicimos el cambio

79
00:03:41,982 --> 00:03:44,030
sin ventana de mantenimiento.

80
00:03:44,030 --> 00:03:47,750
Lo que hicimos fue que iniciamos
escribiendo todos nuestros datos

81
00:03:47,750 --> 00:03:48,810
en ambos lugares--

82
00:03:48,810 --> 00:03:51,110
en SQL y en Mongo.

83
00:03:51,110 --> 00:03:54,260
Y una vez que se realizaron
estas cosas siendo estables y

84
00:03:54,260 --> 00:03:58,980
supimos lo que estábamos haciendo,
migramos lentamente las lecturas

85
00:03:58,980 --> 00:04:00,160
de SQL hacia Mongo.

86
00:04:00,160 --> 00:04:02,750
Así que básicamente estaban
ejecutando ambos sistemas en paralelo.

87
00:04:02,750 --> 00:04:03,730
Exacto.

88
00:04:03,730 --> 00:04:06,515
Y escribiendo a ambos sistemas,
por lo que no dependías de

89
00:04:06,515 --> 00:04:07,280
Mongo por un tiempo.

90
00:04:07,280 --> 00:04:09,040
Te sentiste a gusto con él,
y hasta que por fin cambiaste

91
00:04:09,040 --> 00:04:11,880
estando seguro que estaba
funcionando bien para ti.

92
00:04:11,880 --> 00:04:14,250
Correcto, necesitábamos la
confianza en la tecnología

93
00:04:14,250 --> 00:04:17,660
y asegurarnos que todos los
datos que se suponen que estuvieran

94
00:04:17,660 --> 00:04:18,829
ahí, estaban ahí.

95
00:04:18,829 --> 00:04:21,430
Y una vez que tuvimos eso,
cambiamos las cosas.

96
00:04:21,430 --> 00:04:25,050
OK, en ese punto, ¿cambiaste
completamente Postgres en

97
00:04:25,050 --> 00:04:26,060
ese momento?

98
00:04:26,060 --> 00:04:30,320
En realidad todavía
lo mantenemos en caso

99
00:04:30,320 --> 00:04:31,660
algo salga mal.

100
00:04:31,660 --> 00:04:34,010
Aún teníamos a las escrituras
yendo hacia ambos lugares.

101
00:04:34,010 --> 00:04:37,350
Sólo las lecturas iban a Mongo.

102
00:04:37,350 --> 00:04:41,600
Y lo dejamos así por lo menos
un par de semanas antes que

103
00:04:41,600 --> 00:04:44,880
estuviéramos seguros
que podríamos apagarlo.

104
00:04:44,880 --> 00:04:46,530
¿Cuál es el lenguaje
de tu implementación?

105
00:04:46,530 --> 00:04:48,420
¿Dijiste que fue Scala?

106
00:04:48,420 --> 00:04:49,720
Sí, Scala.

107
00:04:49,720 --> 00:04:55,930
¿Y estaban usando sólo su
driver o hay alguna otra

108
00:04:55,930 --> 00:05:00,410
capa intermediaria que usaron
para comunicarse a Mongo?

109
00:05:00,410 --> 00:05:02,280
Sólo algunos procesos
"por detrás" en Scala.

110
00:05:02,280 --> 00:05:03,380
Para quienes no lo saben,

111
00:05:03,380 --> 00:05:06,220
Scala es un lenguaje compilado
estáticamente que se ejecuta

112
00:05:06,220 --> 00:05:07,870
sobre la JVM.

113
00:05:07,870 --> 00:05:10,930
Se escribe código en una
sintaxiz que es un poco

114
00:05:10,930 --> 00:05:11,750
diferente de Java.

115
00:05:11,750 --> 00:05:14,610
En cierto modo se combina
estilos orientado a objetos

116
00:05:14,610 --> 00:05:16,880
y funcional.

117
00:05:16,880 --> 00:05:20,320
Pero se compila a bytecode
de Java y es completamente

118
00:05:20,320 --> 00:05:23,040
compatible con las
librerías de Java.

119
00:05:23,040 --> 00:05:27,370
El driver que estamos usando es
simplemente el driver de Java

120
00:05:27,370 --> 00:05:28,850
para Mongo de 10gen.

121
00:05:28,850 --> 00:05:29,840
OK.

122
00:05:29,840 --> 00:05:32,960
Todos los estudiantes saben que
MongoDB es "schemaless", y hablamos

123
00:05:32,960 --> 00:05:36,990
mucho acerca de lo bueno que
es en términos de metodologías

124
00:05:36,990 --> 00:05:40,170
ágiles y que permite evolucionar
tu esquema con el tiempo.

125
00:05:40,170 --> 00:05:43,570
¿Puedes contarnos un poco
acerca de cómo tus esquemas han

126
00:05:43,570 --> 00:05:44,300
evolucionado con el tiempo?

127
00:05:44,300 --> 00:05:47,580
Si es que ha sido o no útil,
o si es que el esquema ha sido

128
00:05:47,580 --> 00:05:52,160
bastante estático
en el tiempo en Mongo.

129
00:05:52,160 --> 00:05:52,470
Seguro.

130
00:05:52,470 --> 00:05:55,560
Depende de la colección.

131
00:05:55,560 --> 00:05:58,650
Algunas de nuestras colecciones se
han mantenido estables con el tiempo,

132
00:05:58,650 --> 00:05:59,380
y algunas de ellas no.

133
00:05:59,380 --> 00:06:01,830
Y puedo darte un ejemplo de
nuestra más grande colección,

134
00:06:01,830 --> 00:06:03,980
donde almacenamos 
los "check-ins".

135
00:06:03,980 --> 00:06:06,880
Esta es la que llega a tener 5
millones al día, y en este momento

136
00:06:06,880 --> 00:06:10,220
tiene más de 2 billones
y medio de esas cosas.

137
00:06:10,220 --> 00:06:13,120
Y cuando comenzamos primero
poniendo datos en la

138
00:06:13,120 --> 00:06:18,220
colección, no teníamos
idea de cuánto espacio

139
00:06:18,220 --> 00:06:20,980
terminaría usando eventualmente.

140
00:06:20,980 --> 00:06:23,200
Podríamos haber hecho cálculos
antes de tiempo, pero no creo,

141
00:06:23,200 --> 00:06:25,870
porque eramos nuevos para Mongo.

142
00:06:25,870 --> 00:06:30,760
Y en algún momento nos dimos cuenta
que estábamos almacenando datos de

143
00:06:30,760 --> 00:06:34,330
manera algo menos que
completamente eficiente.

144
00:06:34,330 --> 00:06:39,140
Fuimos capaces de reescribir los
registros mientras el sistema se

145
00:06:39,140 --> 00:06:45,210
mantenía vivo, esto involucraba
ir por un "job" por lotes que

146
00:06:45,210 --> 00:06:48,280
iba y removía ciertos bits
de los datos, añadía

147
00:06:48,280 --> 00:06:48,970
otros datos.

148
00:06:48,970 --> 00:06:54,750
Añadimos nuevos nombres de campos,
en algunos casos, que sean más cortos,

149
00:06:54,750 --> 00:06:57,140
nuevas claves en los documentos que
eran más cortos y que ibamos a

150
00:06:57,140 --> 00:06:59,080
ocupar menos espacio.

151
00:06:59,080 --> 00:07:04,410
Y la forma en que hicimos esto
es manteniendo el viejo campo,

152
00:07:04,410 --> 00:07:08,160
añadimos un nuevo campo y luego en
nuestro código de la aplicación,

153
00:07:08,160 --> 00:07:12,230
hemos sido capaces de manejar
ambos, dependiendo si existía.

154
00:07:12,230 --> 00:07:15,890
El nuevo nombre del campo tendría
preferencia sobre el viejo nombre

155
00:07:15,890 --> 00:07:19,720
de campo, pero aún así es
capaz de leer el viejo nombre

156
00:07:19,720 --> 00:07:21,970
del campo si eso es
todo lo que existía.

157
00:07:21,970 --> 00:07:26,210
De este modo, hemos podido
tener este proceso de migración

158
00:07:26,210 --> 00:07:29,200
ejecutándose sin tener
un tiempo de inactividad.

159
00:07:29,200 --> 00:07:32,830
¿Fue como una migración
lenta donde

160
00:07:32,830 --> 00:07:34,160
estabas migrando
datos activamente?

161
00:07:34,160 --> 00:07:38,720
¿o a veces falló cuando
usaste ese documento que

162
00:07:38,720 --> 00:07:41,020
actualizaría al nuevo esquema?

163
00:07:41,020 --> 00:07:43,050
Fue ambos.

164
00:07:43,050 --> 00:07:45,910
Para nuevos datos, podría ser
inscrito con el nuevo esquema,

165
00:07:45,910 --> 00:07:49,310
pero a menudo no actualiza
los antiguos datos.

166
00:07:49,310 --> 00:07:52,700
Tengo ejecutándose un
proceso por lotes.

167
00:07:52,700 --> 00:07:56,440
Y en pocos días-- incluso tal
vez tomó un par de semanas para

168
00:07:56,440 --> 00:07:57,765
reescribir todos los datos--

169
00:07:57,765 --> 00:08:00,390
poco a poco reescribió
esas claves.

170
00:08:00,390 --> 00:08:01,985
Hablemos un poco
acerca de rendimiento.

171
00:08:01,985 --> 00:08:05,490

172
00:08:05,490 --> 00:08:08,690
En tu colección más
activa, ¿sabes cuántos

173
00:08:08,690 --> 00:08:11,600
índices tienes, sólo
en el orden de magnitud?

174
00:08:11,600 --> 00:08:13,350
¿Tienes 1, 5, 10, 100?

175
00:08:13,350 --> 00:08:16,350
Bueno no podemos tener 100,
pero ¿cuántos índices tienes

176
00:08:16,350 --> 00:08:19,690
en la colección más activa?

177
00:08:19,690 --> 00:08:21,440
Creo que las colecciones
más activas en realidad

178
00:08:21,440 --> 00:08:22,890
tienen menos índices.

179
00:08:22,890 --> 00:08:24,090
Tiene sentido.

180
00:08:24,090 --> 00:08:25,700
Sí porque esas son las más

181
00:08:25,700 --> 00:08:27,250
sensibles a escrituras.

182
00:08:27,250 --> 00:08:31,110
Ellos tienen muy bien definidos
los patrones de acceso.

183
00:08:31,110 --> 00:08:35,510
Para nuestra colección de
"check-ins", creo que tenemos

184
00:08:35,510 --> 00:08:41,059
tres o cuatro índices y
eso que es la más grande.

185
00:08:41,059 --> 00:08:43,690
Y luego para algunas colecciones
más pequeñas donde estamos

186
00:08:43,690 --> 00:08:46,380
poco más holgados en nuestros
patrones de acceso, donde no

187
00:08:46,380 --> 00:08:49,460
somos tan sensibles a las escrituras,
creo que el mayor número de

188
00:08:49,460 --> 00:08:53,550
índices que tenemos aún
estaría por debajo de 10.

189
00:08:53,550 --> 00:08:56,650
¿Utilizan nuestros
índices geoespaciales?

190
00:08:56,650 --> 00:08:57,680
Lo hacemos.

191
00:08:57,680 --> 00:09:02,190
Cuando migramos nuestra colección
de lugares, que es una de las

192
00:09:02,190 --> 00:09:06,860
primeras cosas que migramos
de Postgres to Mongo, uno de

193
00:09:06,860 --> 00:09:11,330
los grandes beneficios de Mongo
es que tiene ya por defecto

194
00:09:11,330 --> 00:09:12,390
indexación geospacial.

195
00:09:12,390 --> 00:09:16,830
Postgres también lo tiene, pero
no fue tan fácil de utilizar,

196
00:09:16,830 --> 00:09:20,520
y no estábamos
familiarizados con él.

197
00:09:20,520 --> 00:09:25,450
Por ello cuando estábamos en
Postgres, estábamos haciendo nuestras

198
00:09:25,450 --> 00:09:29,660
consultas limitando cuadrados en
crudo, como obtener el lugar donde

199
00:09:29,660 --> 00:09:32,770
la latitud está entre
este y otro valor, y la

200
00:09:32,770 --> 00:09:37,360
longitud está entre este y
otro valor, que funciona

201
00:09:37,360 --> 00:09:39,540
hasta cierto punto.

202
00:09:39,540 --> 00:09:43,840
Y cuando nos mudamos a Mongo, nos
cambiamos al uso de geoindexación

203
00:09:43,840 --> 00:09:47,826
por defecto, y fuimos capaces
de manejar una mayor carga en un

204
00:09:47,826 --> 00:09:49,400
solo equipo.

205
00:09:49,400 --> 00:09:51,690
¿Utilizan el modelo 2D?

206
00:09:51,690 --> 00:09:55,962
¿O utilizan el nuevo
modelo esférico?

207
00:09:55,962 --> 00:09:58,710
En ese momento-- esto fue
hace un par de años--

208
00:09:58,710 --> 00:10:02,950
en ese momento, estábamos
usando el modelo 2D.

209
00:10:02,950 --> 00:10:08,000
Y actualmente, creo que aún
estámos usando el modelo 2D en

210
00:10:08,000 --> 00:10:10,710
colecciones que
tengan geoindexación.

211
00:10:10,710 --> 00:10:11,710
OK.

212
00:10:11,710 --> 00:10:12,250
Bien.

213
00:10:12,250 --> 00:10:15,000
Que significa que aún con la
forma en que solían estar haciendo

214
00:10:15,000 --> 00:10:16,540
con los límites de
latitud y longitud,

215
00:10:16,540 --> 00:10:18,370
obtienen cuadrados.

216
00:10:18,370 --> 00:10:21,430
Y ahora está obteniendo
círculos, pero podrían ser

217
00:10:21,430 --> 00:10:24,700
elipsis, porque las líneas de
latitud y longitud podrían

218
00:10:24,700 --> 00:10:29,280
no estar igualmente
equidistantes, supongo.

219
00:10:29,280 --> 00:10:33,670
A veces hemos tenido
problemas con eso.

220
00:10:33,670 --> 00:10:35,150
Más lejos del ecuador, supongo.

221
00:10:35,150 --> 00:10:36,100
Correcto, eso es.

222
00:10:36,100 --> 00:10:41,280
En muchas ciudades del norte,
como Reykjavik, Iceland,

223
00:10:41,280 --> 00:10:46,560
tenemos problemas donde el valor a
trabajar en la base de datos tiene

224
00:10:46,560 --> 00:10:52,540
que encontrar cierta área limitada
que es mucho más alta que en

225
00:10:52,540 --> 00:10:53,850
otros lugares del mundo.

226
00:10:53,850 --> 00:10:55,100
Interesante.

227
00:10:55,100 --> 00:10:57,150

228
00:10:57,150 --> 00:11:01,790
Ya que estamos hablando
de rendimiento, ¿cómo

229
00:11:01,790 --> 00:11:04,400
monitorean el sistema para
asegurarse que tienen un buen

230
00:11:04,400 --> 00:11:05,970
rendimiento--

231
00:11:05,970 --> 00:11:07,480
buscan sus consultas lentas?

232
00:11:07,480 --> 00:11:13,050
¿Cuál es la forma habitual de
asegurarse que un desarrollador

233
00:11:13,050 --> 00:11:17,390
está escribiendo consultas que van
hacia los índices y que nadie va a

234
00:11:17,390 --> 00:11:21,100
estropear el rendimiento
poniendo una consulta

235
00:11:21,100 --> 00:11:24,210
lenta?, que es frecuente.

236
00:11:24,210 --> 00:11:29,480
En nuestra capa de aplicación,
estamos usando una librería que

237
00:11:29,480 --> 00:11:31,310
escribimos llamada Rogue.

238
00:11:31,310 --> 00:11:34,180
Esta es una librería en Scala.

239
00:11:34,180 --> 00:11:36,570
Y esto nos permite definir un
esquema para cada documento.

240
00:11:36,570 --> 00:11:39,620
Esto también permite definir
estáticamente qué indices

241
00:11:39,620 --> 00:11:43,410
estás usando en
la base de datos.

242
00:11:43,410 --> 00:11:47,450
En el mismo código, cuando
escribes una consulta que no

243
00:11:47,450 --> 00:11:51,630
utiliza un índice, en realidad vas
a obtener un error de compilación--

244
00:11:51,630 --> 00:11:52,100
Eso está genial.

245
00:11:52,100 --> 00:11:53,910
--en el código de tu aplicación.

246
00:11:53,910 --> 00:11:56,780
Y hay una manera de sobreescribir
esto, por supuesto, porque

247
00:11:56,780 --> 00:12:01,680
a veces deseas hacer un escaneo
completo de consulta, pero si no

248
00:12:01,680 --> 00:12:04,460
lo especificas, obtendrás
un error de compilación.

249
00:12:04,460 --> 00:12:08,970
Y no podrás ejecutar tu código.

250
00:12:08,970 --> 00:12:14,520
La selección de índices
no es completamente obvia.

251
00:12:14,520 --> 00:12:16,840
Tenemos un optimizador de
consultas y a veces hay

252
00:12:16,840 --> 00:12:18,030
distintos planes.

253
00:12:18,030 --> 00:12:22,920
¿Cómo sabes, para alguna consulta
dada, qué índice de MongoDB

254
00:12:22,920 --> 00:12:27,840
usaría sin ejecutarla?

255
00:12:27,840 --> 00:12:31,260
En primer lugar, cuando estamos
diseñamos una colección, pasamos

256
00:12:31,260 --> 00:12:35,430
por un proceso de revisión
interna donde la gente describe

257
00:12:35,430 --> 00:12:38,840
los datos que desean almacenar,
qué patrones de consulta van a

258
00:12:38,840 --> 00:12:42,710
ser, qué patrones de
actualización van a ser, 

259
00:12:42,710 --> 00:12:45,400
cómo ellos se relacionan a las
otras cosas que ya sabemos algo

260
00:12:45,400 --> 00:12:46,050
que pensamos.

261
00:12:46,050 --> 00:12:49,640
Como, están añadiendo
algo que se relacionará

262
00:12:49,640 --> 00:12:51,840
a alguna acción,
como algo que se puede

263
00:12:51,840 --> 00:12:53,080
acceder en cada "check-in".

264
00:12:53,080 --> 00:12:55,190
O algo que se tendrá
acceso en todas las

265
00:12:55,190 --> 00:12:57,210
consultas de recomendaciones.

266
00:12:57,210 --> 00:13:01,330
Esa es la manera de entender
el uso, y luego podemos decidir

267
00:13:01,330 --> 00:13:04,580
qué índices deseamos construir.

268
00:13:04,580 --> 00:13:10,780
Y una vez que lo tenemos, también
sabemos qué consultas vamos a

269
00:13:10,780 --> 00:13:12,030
estar ejecutando.

270
00:13:12,030 --> 00:13:14,150

271
00:13:14,150 --> 00:13:16,800
Uno de los problemas que
podrías tener en Mongo, es

272
00:13:16,800 --> 00:13:19,635
que podrías ejecutar una
oonsulta y podría usar

273
00:13:19,635 --> 00:13:22,570
un índice no deseado.

274
00:13:22,570 --> 00:13:24,430
Y hemos visto que
sucedió antes, pero

275
00:13:24,430 --> 00:13:26,420
es un caso muy extraño.

276
00:13:26,420 --> 00:13:31,850
Como, muy a menudo el índice
que es usado es el único que

277
00:13:31,850 --> 00:13:34,940
esperamos sea usado.

278
00:13:34,940 --> 00:13:38,370
¿En realidad lo tienen
mapeado estáticamente?

279
00:13:38,370 --> 00:13:39,650
Lo tenemos mapeado estáticamente,
pero Mongo tiene algo de

280
00:13:39,650 --> 00:13:42,900
inteligencia por defecto donde
la decisión de qué índice

281
00:13:42,900 --> 00:13:45,100
usar puede a veces
ser ambigua.

282
00:13:45,100 --> 00:13:48,970
Y creo que hay heurística
en Mongo basada en la

283
00:13:48,970 --> 00:13:53,660
cantidad de tiempo que una
consulta toma usando un índice

284
00:13:53,660 --> 00:13:56,190
y otro, decidirá ir con uno u otro.

285
00:13:56,190 --> 00:13:56,540
Eso es correcto.

286
00:13:56,540 --> 00:13:59,330
Eso es lo que hace.

287
00:13:59,330 --> 00:14:03,330
Y a veces he visto que tomó
la decisión equivocada.

288
00:14:03,330 --> 00:14:04,530
¿Usaste "hint" en aquel caso?

289
00:14:04,530 --> 00:14:07,660
Sí en aquel caso, añadimos
un "hint" a la consulta que

290
00:14:07,660 --> 00:14:12,270
supimos que siempre va
a usar el índice correcto.

291
00:14:12,270 --> 00:14:14,860
¿Los desarrolladores
necesitan escribir el "hint"?

292
00:14:14,860 --> 00:14:17,450
¿O es automáticamente construido
en esta capa de interfaz para eso,

293
00:14:17,450 --> 00:14:20,058
siempre y cuando--

294
00:14:20,058 --> 00:14:21,940
¿ellos tienen que escribir
el "hint" o está escrito

295
00:14:21,940 --> 00:14:22,450
defecto?

296
00:14:22,450 --> 00:14:24,860
Sí, el desarrollador
escribirá el "hint".

297
00:14:24,860 --> 00:14:27,730
Y porque tenemos los índices
estáticamente definidos como

298
00:14:27,730 --> 00:14:30,685
parte de nuestra definición
de esquema, todos ellos tienen

299
00:14:30,685 --> 00:14:34,330
que hacer como un ".hint()" y
luego hacer referencia a este

300
00:14:34,330 --> 00:14:36,370
indice definido estáticamente.

301
00:14:36,370 --> 00:14:37,810
OK.

302
00:14:37,810 --> 00:14:39,700
Muy bien.

303
00:14:39,700 --> 00:14:47,840
Y luego cuando despliegas el
nuevo código, ¿mantienes el

304
00:14:47,840 --> 00:14:48,570
sistema en ejecución?

305
00:14:48,570 --> 00:14:52,600
¿Desactivas partes del
sistema para hacerlo?

306
00:14:52,600 --> 00:14:55,160
Si tienes que migrar el
esquema, o si cambias el esquema

307
00:14:55,160 --> 00:14:59,820
un poco, ¿cómo lidias con eso
en el sistema en producción?

308
00:14:59,820 --> 00:15:04,020
Hemos tenido algunos casos en los
que hemos hecho las migraciones más

309
00:15:04,020 --> 00:15:06,435
complicadas que la
migración de "check-ins"

310
00:15:06,435 --> 00:15:07,975
que describí antes.

311
00:15:07,975 --> 00:15:10,580

312
00:15:10,580 --> 00:15:16,270
En la reescritura del esquema
de "check-in", pudimos usar la

313
00:15:16,270 --> 00:15:20,360
misma definición de esquema
en nuestra aplicación basándonos

314
00:15:20,360 --> 00:15:24,080
en el cambio de documento,
porque no cambiamos de

315
00:15:24,080 --> 00:15:25,640
manera drástica.

316
00:15:25,640 --> 00:15:28,810
Pero en otros casos,
hemos hecho cambios bastante

317
00:15:28,810 --> 00:15:31,950
drásticos y sería demasiado
arriesgado para hacer algo

318
00:15:31,950 --> 00:15:33,950
de ese tipo.

319
00:15:33,950 --> 00:15:37,380
Lo que hemos hecho en estos
caso es crear una colección

320
00:15:37,380 --> 00:15:39,720
completa de datos en paralelo.

321
00:15:39,720 --> 00:15:44,970
Un ejemplo de esto es nuestros
datos de gráficos de amigos.

322
00:15:44,970 --> 00:15:51,170
Iniciamos con un gráfico de
amigos que en realidad sólo tenía

323
00:15:51,170 --> 00:15:53,260
un registro
por cada relación.

324
00:15:53,260 --> 00:15:56,480
Si yo soy tu amigo,
habría una relación que

325
00:15:56,480 --> 00:15:58,830
señale esto--

326
00:15:58,830 --> 00:15:59,710
en esa dirección.

327
00:15:59,710 --> 00:16:02,530
Como, yo a tú-- mi identificador
de usuario hacia el tuyo.

328
00:16:02,530 --> 00:16:06,700
Y habría otro que
señala de ti hacia mi.

329
00:16:06,700 --> 00:16:10,150
Y de esa manera, cuando hicimos una
consulta en quienes son mis amigos,

330
00:16:10,150 --> 00:16:14,000
que acaba de ser la
búsqueda que digamos

331
00:16:14,000 --> 00:16:17,060
desde la clave en este registro.

332
00:16:17,060 --> 00:16:20,130
Y cuando estamos haciendo una
consulta de quienes son tus amigos,

333
00:16:20,130 --> 00:16:23,300
también estamos buscando desde la
clave, y tendría que haber sólo

334
00:16:23,300 --> 00:16:26,350
dos registros separados por cada
lado de la relación para hacer

335
00:16:26,350 --> 00:16:29,420
más fácil la consulta.

336
00:16:29,420 --> 00:16:32,240
Nos dimos cuenta que
eso se estaba usando--

337
00:16:32,240 --> 00:16:35,090
ese tipo de representación de
gráficos de amigos estaba usando

338
00:16:35,090 --> 00:16:37,895
mucho espacio de lo
necesario en Mongo.

339
00:16:37,895 --> 00:16:41,470
Básicamente denormalizamos
esos gráficos de amigos.

340
00:16:41,470 --> 00:16:44,810
En lugar de almacenar un registro
por relación, almacenamos

341
00:16:44,810 --> 00:16:49,530
un registro por usuario y
en ese registro tuvimos

342
00:16:49,530 --> 00:16:55,330
una lista de todos los
amigos que ellos tenían.

343
00:16:55,330 --> 00:17:01,640
Así para tu registro de amigos
habría una lista de cada identificador

344
00:17:01,640 --> 00:17:03,350
de usuario que tus amigos tenían.

345
00:17:03,350 --> 00:17:05,290
Y lo mismo para mi
registro de amigos.

346
00:17:05,290 --> 00:17:09,014
Ahora, ¿la relación de
amistad en Foursquare es

347
00:17:09,014 --> 00:17:10,470
asimétrico?

348
00:17:10,470 --> 00:17:12,069
¿o es simétrico?

349
00:17:12,069 --> 00:17:14,690
¿Yo puedo seguirte
sin que tu me sigas?

350
00:17:14,690 --> 00:17:16,420
Mayormente, es simétrico.

351
00:17:16,420 --> 00:17:20,490
Tenemos algunos casos
raros donde no lo es.

352
00:17:20,490 --> 00:17:24,770
Pero el proceso de reescritura
de ese esquema fue bastante

353
00:17:24,770 --> 00:17:25,550
complicado.

354
00:17:25,550 --> 00:17:31,810
Así que lo que hicimos fue en
realidad tener ambos esquemas

355
00:17:31,810 --> 00:17:37,480
ejecutándose en paralelo, y
mantenerlos sincronizados,

356
00:17:37,480 --> 00:17:41,050
utilizamos el "oplog" de Mongo.

357
00:17:41,050 --> 00:17:44,910
Escribimos una aplicación que
siga al "oplog" para todas

358
00:17:44,910 --> 00:17:49,170
las modificaciones de la
colección original y luego

359
00:17:49,170 --> 00:17:52,660
transforme eso de manera
que debería verse en el

360
00:17:52,660 --> 00:17:54,230
nuevo esquema.

361
00:17:54,230 --> 00:17:58,220
Fue una migración muy complicada.

362
00:17:58,220 --> 00:18:03,300
Eso fue una buena transición,
no hemos repasado mucho acerca de

363
00:18:03,300 --> 00:18:06,330
asuntos operacionales en este
curso porque no es el curso de

364
00:18:06,330 --> 00:18:11,400
DBA, pero quiero darle a los
estudiantes alguna idea de

365
00:18:11,400 --> 00:18:13,850
cómo es operacionalmente.

366
00:18:13,850 --> 00:18:17,380
En primer lugar, ¿ejecutan
con Sharding, correcto?

367
00:18:17,380 --> 00:18:18,310
Sí.

368
00:18:18,310 --> 00:18:24,110
¿Y utilizan AWS?

369
00:18:24,110 --> 00:18:26,930
Tenemos en realidad un
entorno distribuido.

370
00:18:26,930 --> 00:18:30,920
Nuestros servidores de aplicación
se ejecutan en AWS y algunas otras

371
00:18:30,920 --> 00:18:34,640
fuentes, pero nuestros servidores
de base de datos Mongo, en realidad

372
00:18:34,640 --> 00:18:38,390
en nuestros propios servidores.

373
00:18:38,390 --> 00:18:41,900
Y eso ha sido una evolución
para ti, porque lo ejecutaste

374
00:18:41,900 --> 00:18:42,860
en AWS.

375
00:18:42,860 --> 00:18:46,840
Empezamos en AWS y luego
recientemente migramos a

376
00:18:46,840 --> 00:18:49,380
nuestra propia infraestructura.

377
00:18:49,380 --> 00:18:51,700
Bien, he visto algunas presentaciones
de Foursquare hablando

378
00:18:51,700 --> 00:18:52,920
acerca de eso.

379
00:18:52,920 --> 00:18:57,110
Algunos de los primeros problemas
que tuvieronfue con el rendimiento de EBS.

380
00:18:57,110 --> 00:19:01,120
EBS es el Elastic block
store en Amazon.

381
00:19:01,120 --> 00:19:07,240
Es esencialmente un sistema
de archivos basado en la red.

382
00:19:07,240 --> 00:19:10,040
Y no estaban obteniendo el
rendimiento que necesitaban y

383
00:19:10,040 --> 00:19:12,596
habían otros problemas.

384
00:19:12,596 --> 00:19:15,430
Y hablaban de la
migración fuera de--

385
00:19:15,430 --> 00:19:18,720
vi esto quizá hace seis
meses-- fuera de Amazon sólo

386
00:19:18,720 --> 00:19:21,660
para esa parte.

387
00:19:21,660 --> 00:19:23,310
¿Ha sido una buena migración?

388
00:19:23,310 --> 00:19:26,440
¿Ayudaste a resolver los
problemas que tuvieron cuando

389
00:19:26,440 --> 00:19:29,120
migraron a hardware dedicado?

390
00:19:29,120 --> 00:19:30,020
Sí, lo hice.

391
00:19:30,020 --> 00:19:36,080
El problema que tuvimos
teniendo EBS fue

392
00:19:36,080 --> 00:19:39,570
porque es un servicio en
la red, de vez en cuando

393
00:19:39,570 --> 00:19:44,610
podías ver muchas grandes
variaciones en la latencia

394
00:19:44,610 --> 00:19:47,470
para operaciones en disco.

395
00:19:47,470 --> 00:19:50,560
Y además de eso, podías
ver extremas variaciones

396
00:19:50,560 --> 00:19:54,990
donde el I/O se bloqueaba por
completo en el equipo, y

397
00:19:54,990 --> 00:19:57,440
eso es porque hay algún
tiempo de proceso por detrás

398
00:19:57,440 --> 00:20:00,950
ejecutándose en los datos
para hacer un espejo en

399
00:20:00,950 --> 00:20:04,060
las cosas de Amazon.

400
00:20:04,060 --> 00:20:06,830
Y sin aplicación
lidia con el disco

401
00:20:06,830 --> 00:20:08,020
completando el bloqueo.

402
00:20:08,020 --> 00:20:09,040
No, no es fácil.

403
00:20:09,040 --> 00:20:11,060
Las aplicaciones no
esperan que eso suceda.

404
00:20:11,060 --> 00:20:14,300
Podría haber un error de I/O
que quizá en la aplicación

405
00:20:14,300 --> 00:20:17,450
sepa lidiar con esto, pero
una aplicación no trata bien

406
00:20:17,450 --> 00:20:22,510
con bloqueos indefinidos de I/O.
Y Mongo no trata muy

407
00:20:22,510 --> 00:20:25,170
bien con esto.

408
00:20:25,170 --> 00:20:31,860
El problema que tuvimos fue
que Mongo tiene esta funcionalidad

409
00:20:31,860 --> 00:20:36,180
maravillosa de replicación, de conjuntos
de réplicas, donde puedes tener un

410
00:20:36,180 --> 00:20:40,200
primario y múltiples
secundarios, y la idea que

411
00:20:40,200 --> 00:20:41,820
tus escrituras van al primario.

412
00:20:41,820 --> 00:20:42,910
Tienes múltiples secundarios.

413
00:20:42,910 --> 00:20:46,300
Si uno de los servidores
cae, tienes redundancia.

414
00:20:46,300 --> 00:20:49,505
Si el primario cae, se
ejecutará una elección y

415
00:20:49,505 --> 00:20:52,060
un secundario tomará el lugar
y se convertirá en primario.

416
00:20:52,060 --> 00:20:53,840
En pocos segundos,
tus escrituras tendrán

417
00:20:53,840 --> 00:20:54,650
un nuevo lugar a tomar.

418
00:20:54,650 --> 00:20:58,190
Si uno de los secundarios
cae, está bien.

419
00:20:58,190 --> 00:21:02,020
Las consultas serán enviadas
a los otros secundarios.

420
00:21:02,020 --> 00:21:08,130
Pero ese mecanismo de conmutación
por error se basa en un tipo de

421
00:21:08,130 --> 00:21:11,960
interrupción, como un proceso
muerto o equipo muerto, o

422
00:21:11,960 --> 00:21:14,440
es inaccesible en la red.

423
00:21:14,440 --> 00:21:19,040
Cuando el proceso es
simplemente muy lento porque

424
00:21:19,040 --> 00:21:23,520
el disco no retorna más
las llamadas de I/O.

425
00:21:23,520 --> 00:21:27,260
Mongo no sabe cómo
lidiar con eso también.

426
00:21:27,260 --> 00:21:31,410
Lo que veríamos es que esta
maravillosa conmutación por error

427
00:21:31,410 --> 00:21:36,430
no funcionaba por estos
problemas de ejecutar en

428
00:21:36,430 --> 00:21:37,640
base a discos de red.

429
00:21:37,640 --> 00:21:40,210
¿Y verías esa inestabilidad?

430
00:21:40,210 --> 00:21:41,700
Verías--

431
00:21:41,700 --> 00:21:44,340
¿qué pensaría el sistema que una
réplica se cae, e intentaría

432
00:21:44,340 --> 00:21:47,725
llevarlo a cabo y
traerlo de regreso?

433
00:21:47,725 --> 00:21:51,360
No lo veríamos,
en realidad, depende de

434
00:21:51,360 --> 00:21:56,370
dónde el problema ocurrió,
tendríamos la consultas de tiempo

435
00:21:56,370 --> 00:21:57,540
de respuesta en el backend.

436
00:21:57,540 --> 00:22:02,300
Si nuestra aplicación intentó de
hacer una escritura, y el primario

437
00:22:02,300 --> 00:22:04,760
tuvo un problema, que la escritura
culminó su tiempo de espera.

438
00:22:04,760 --> 00:22:07,410
Si ellos intentan hacer una
lectura al secundario--

439
00:22:07,410 --> 00:22:09,231
esos podría terminar
el tiempo de espera.

440
00:22:09,231 --> 00:22:10,481
¿Usan el modo seguro?

441
00:22:10,481 --> 00:22:13,270

442
00:22:13,270 --> 00:22:14,900
Concernencia de escritura--

443
00:22:14,900 --> 00:22:17,675
¿llaman a "getLastError"
para asegurarse que

444
00:22:17,675 --> 00:22:19,450
tu consulta está completa?

445
00:22:19,450 --> 00:22:20,980
Sí, lo hacemos en realidad.

446
00:22:20,980 --> 00:22:26,830
Ejecutamos "getLastError" con
"safe", "WriteConcern" igual "safe".

447
00:22:26,830 --> 00:22:31,010
Y en el nuevo sistema que
reubicaron, ¿usan discos

448
00:22:31,010 --> 00:22:33,400
de estado sólido o usan
discos mecánicos?

449
00:22:33,400 --> 00:22:36,920
Sí, usamos discos
de estado sólido.

450
00:22:36,920 --> 00:22:39,400
Supongo que Amazon no tenía
discos de estado sólidos cuando

451
00:22:39,400 --> 00:22:41,550
tomaron la decisión de
hacer esa transición.

452
00:22:41,550 --> 00:22:42,540
¿Es eso cierto?

453
00:22:42,540 --> 00:22:44,750
Eso es cierto.

454
00:22:44,750 --> 00:22:48,890
¿Tienes alguna experiencia con
intentar usar discos de estado

455
00:22:48,890 --> 00:22:50,290
sólido en Amazon para ver si
obtienes el mismo resultado?

456
00:22:50,290 --> 00:22:53,000

457
00:22:53,000 --> 00:22:53,690
No.

458
00:22:53,690 --> 00:22:56,970
La información que tengo de
otras personas es que en realidad

459
00:22:56,970 --> 00:22:58,730
funciona como dicen.

460
00:22:58,730 --> 00:23:02,630
Estamos ejecutando discos de estado
sólido en nuestros propios equipos,

461
00:23:02,630 --> 00:23:05,570
y asumo que las
prestaciones de rendimiento

462
00:23:05,570 --> 00:23:07,100
serían algo similar.

463
00:23:07,100 --> 00:23:12,370
Así que en realidad habría
solucionado nuestros problemas

464
00:23:12,370 --> 00:23:14,470
ejecutando en Amazon,
si tuviéramos acceso a esa

465
00:23:14,470 --> 00:23:16,440
tecnología en el momento.

466
00:23:16,440 --> 00:23:20,280
Pero hay razones adicionales
para migrar a nuestro propia

467
00:23:20,280 --> 00:23:22,500
infraestructura de servidores.

468
00:23:22,500 --> 00:23:26,580
La más grande, además de esta
preocupación de la fiabilidad,

469
00:23:26,580 --> 00:23:30,910
es que ha sido realidad
dirigido, es el costo.

470
00:23:30,910 --> 00:23:35,660
Pensamos que porque estamos
en una cierta escala, podemos

471
00:23:35,660 --> 00:23:40,950
dedicar una cierta cantidad de
dinero comprando un conjunto

472
00:23:40,950 --> 00:23:44,250
fijo de capacidad y en realidad
hace cosas un poco más baratas

473
00:23:44,250 --> 00:23:45,282
que en Amazon.

474
00:23:45,282 --> 00:23:47,570
Eso realmente no tiene
sentido hasta que llegamos

475
00:23:47,570 --> 00:23:48,760
a un cierto tamaño.

476
00:23:48,760 --> 00:23:50,085
Sí, sin duda.

477
00:23:50,085 --> 00:23:52,800

478
00:23:52,800 --> 00:23:57,110
Cuando eres pequeño, la idea de
agregar una persona para manejar

479
00:23:57,110 --> 00:24:01,910
esas cosas empequeñece el costo
de cualquier marcado ligero que

480
00:24:01,910 --> 00:24:03,790
Amazon ha terminado
haciendo por ti mismo.

481
00:24:03,790 --> 00:24:04,520
Claro.

482
00:24:04,520 --> 00:24:05,370
Sí.

483
00:24:05,370 --> 00:24:07,120
Supongo cuando obtienes
un cierto tamaño,

484
00:24:07,120 --> 00:24:08,370
que no es más grande.

485
00:24:08,370 --> 00:24:13,690

486
00:24:13,690 --> 00:24:17,840
Pensé que quizá podríamos ir más
hacia la vida de los "check-ins"

487
00:24:17,840 --> 00:24:21,580
y hacer eso en frente de
una pizarra, si eso estaría

488
00:24:21,580 --> 00:24:22,890
bien para ti.

489
00:24:22,890 --> 00:24:26,520
Y vamos a la pizarra, para
que puedas mostrar a todos--

490
00:24:26,520 --> 00:24:28,440
darnos una visión de alto nivel
de lo que pasa cuando alguien

491
00:24:28,440 --> 00:24:30,480
hace "check-in",
en relación con MongoDB.

492
00:24:30,480 --> 00:24:32,550
Claro, está bien.

493
00:24:32,550 --> 00:24:35,550
De acuerdo bueno, vamos
a estar de regreso.

494
00:24:35,550 --> 00:24:38,850
OK, bienvenidos a nuestra
sala de reuniones

495
00:24:38,850 --> 00:24:39,790
con limitaciones acústicas.

496
00:24:39,790 --> 00:24:43,230
Llévanos a revisar el
ciclo de vida de un

497
00:24:43,230 --> 00:24:47,840
"check-in", mostrándonos cómo
ésto interactúa con MongoDB.

498
00:24:47,840 --> 00:24:51,730
Un "check-in" es algo
que se puede hacer en tu

499
00:24:51,730 --> 00:24:55,030
iPhone, o tu BlackBerry,
o tu dispositivo Android.

500
00:24:55,030 --> 00:24:57,460
Y lo que estás haciendo es que
estás publicando una determinada

501
00:24:57,460 --> 00:24:59,840
cantidad de información hacia el
servidor de aplicación de Foursquare,

502
00:24:59,840 --> 00:25:05,030
y luego estamos haciendo un
ida y vuelta con nuestras bases

503
00:25:05,030 --> 00:25:07,950
de datos Mongo para
almacenar esa información

504
00:25:07,950 --> 00:25:09,810
y convertir tu resultado.

505
00:25:09,810 --> 00:25:14,050
Así que voy a mostrar lo
básico de cómo eso sucede.

506
00:25:14,050 --> 00:25:17,740
Básicamente hay tres
actores en el sistema.

507
00:25:17,740 --> 00:25:20,800
Está el dispositivo
del usuario por aquí,

508
00:25:20,800 --> 00:25:24,030
que podría ser un iPhone.

509
00:25:24,030 --> 00:25:30,350
Luego está nuestro servidor
de aplicaciones aquí, y como

510
00:25:30,350 --> 00:25:33,820
mencioné, ésto es
código escrito en Scala.

511
00:25:33,820 --> 00:25:37,470
Y está ejecutándose sobre el
driver de Java para Mongo.

512
00:25:37,470 --> 00:25:41,593
Y luego tenemos nuestra
base de datos Mongo por aquí.

513
00:25:41,593 --> 00:25:50,250

514
00:25:50,250 --> 00:25:55,000
Lo primero que sucede es
que el usuario toma su

515
00:25:55,000 --> 00:25:58,960
dispositivo, ubica el
lugar en el que está,

516
00:25:58,960 --> 00:26:01,770
hace "clic" en eso y
luego hace "check-in".

517
00:26:01,770 --> 00:26:08,030
Y la información que se envía
a nuestra aplicación, es un

518
00:26:08,030 --> 00:26:18,050
token para la autenticación, un
identificador del lugar, y una

519
00:26:18,050 --> 00:26:19,960
información de latitud y longitud
del dispositivo acerca de donde

520
00:26:19,960 --> 00:26:21,210
se encuentran ahora.

521
00:26:21,210 --> 00:26:23,650

522
00:26:23,650 --> 00:26:26,380
Cuando la aplicación tiene
esa información, lo primero

523
00:26:26,380 --> 00:26:30,380
que necesita es
autenticar al usuario.

524
00:26:30,380 --> 00:26:36,040
Toma aquel token que
viene y ejecuta una

525
00:26:36,040 --> 00:26:37,810
consulta hacia Mongo--

526
00:26:37,810 --> 00:26:42,500

527
00:26:42,500 --> 00:26:45,190
token.

528
00:26:45,190 --> 00:26:49,570
Básicamente está haciendo
una consulta simple donde el

529
00:26:49,570 --> 00:26:51,580
identificador es el token.

530
00:26:51,580 --> 00:26:55,890
Y el resultado que retorna
es un registro que tiene un

531
00:26:55,890 --> 00:26:59,230
mapeo al identificador del
usuario para aquel token.

532
00:26:59,230 --> 00:27:00,110
OK.

533
00:27:00,110 --> 00:27:03,420
Obtiene el identificador de usuario,
que es un entero de algún orden.

534
00:27:03,420 --> 00:27:03,790
Correcto.

535
00:27:03,790 --> 00:27:06,370
El identificador de
usuario en un entero.

536
00:27:06,370 --> 00:27:12,600
Ahora, para Mongo, tenemos
el identificador de usuario.

537
00:27:12,600 --> 00:27:16,230
Y la razón para que el identificador
de usuario sea un entero y no un

538
00:27:16,230 --> 00:27:20,700
ObjectId normal de Mongo, es porque
venimos de un sistema heredado de

539
00:27:20,700 --> 00:27:27,070
SQL donde el identificador fue
un entero autoincremental.

540
00:27:27,070 --> 00:27:30,220
Y porque se preserva el
identificador de usuario

541
00:27:30,220 --> 00:27:33,360
como clave foránea, hubiera
sido demasiado de trabajo migrar,

542
00:27:33,360 --> 00:27:37,100
por lo que se mantuvo
como un entero.

543
00:27:37,100 --> 00:27:39,850
¿Y el nombre de usuario
se puede modificar

544
00:27:39,850 --> 00:27:40,410
en tu sistema entonces?

545
00:27:40,410 --> 00:27:43,930
Sí, el nombre de usuario
se puede modificar.

546
00:27:43,930 --> 00:27:48,480
Nuestro documento en Mongo para
un registro de usuario tiene el

547
00:27:48,480 --> 00:27:52,330
"_id" como un entero,
y hay campos para el

548
00:27:52,330 --> 00:27:54,830
nombre, apellido, correo, etcétera.

549
00:27:54,830 --> 00:27:57,890

550
00:27:57,890 --> 00:28:02,040
Así que una vez que tenemos este identificador
en el servidor de aplicaciones, queremos

551
00:28:02,040 --> 00:28:05,620
consultar este registro de usuario
que tiene información más detallada

552
00:28:05,620 --> 00:28:08,220
acerca del usuario,
porque una de las cosas

553
00:28:08,220 --> 00:28:12,230
en el registro de usuario está el
identificador de su último "check-in".

554
00:28:12,230 --> 00:28:17,180
Y resulta que lo
necesitaremos más adelante.

555
00:28:17,180 --> 00:28:23,080
Luego hacemos una consulta a Mongo con
el identificador de usuario, y lo que

556
00:28:23,080 --> 00:28:26,510
retorna es el registro
completo de usuario.

557
00:28:26,510 --> 00:28:31,330

558
00:28:31,330 --> 00:28:31,980
Te entiendo.

559
00:28:31,980 --> 00:28:33,490
OK.

560
00:28:33,490 --> 00:28:35,660
Va hacia el servidor
de aplicaciones--

561
00:28:35,660 --> 00:28:36,650
va a eso.

562
00:28:36,650 --> 00:28:38,970
Eso está en el servidor
de aplicaciones ahora.

563
00:28:38,970 --> 00:28:41,780
Lo siguiente que necesitamos
es que tenemos que tomar este

564
00:28:41,780 --> 00:28:46,770
identificador del lugar, y
asegurar que es un lugar real.

565
00:28:46,770 --> 00:28:49,650
Si no lo es, entonces retornará
un error hacia el usuario.

566
00:28:49,650 --> 00:28:53,080
Ejecutamos una consulta con
este identificador de lugar.

567
00:28:53,080 --> 00:28:58,350
Y el identificador de lugar es
un ObjectId estándar de Mongo.

568
00:28:58,350 --> 00:29:05,850
Enviamos una consulta con el
identificador de lugar y obtenemos

569
00:29:05,850 --> 00:29:07,750
el registro del lugar.

570
00:29:07,750 --> 00:29:09,290
O no-- en caso fallemos.

571
00:29:09,290 --> 00:29:18,390

572
00:29:18,390 --> 00:29:20,400
Y tiene en cuenta que éstas
son distintas colecciones.

573
00:29:20,400 --> 00:29:24,595
Esto sería una colección
llamada "oauth_tokens", esta

574
00:29:24,595 --> 00:29:27,325
es una consulta contra una colección
llamada "users", esta es una consulta

575
00:29:27,325 --> 00:29:30,120
contra una colección
llamada "venues".

576
00:29:30,120 --> 00:29:32,090
¿Cuál de éstas es
la más pequeña?

577
00:29:32,090 --> 00:29:36,970
En realidad todas ellas
están con Sharding.

578
00:29:36,970 --> 00:29:42,220
Estoy simplificando cosas un poco
aquí, pero algunos de estas están en

579
00:29:42,220 --> 00:29:44,100
clústers de Mongo
completamente diferentes.

580
00:29:44,100 --> 00:29:47,020
Tenemos la información
de lugares almacenada en

581
00:29:47,020 --> 00:29:50,620
un clúster de Mongo y
la información de usuarios

582
00:29:50,620 --> 00:29:51,930
en uno diferente.

583
00:29:51,930 --> 00:29:56,990
Y estos clústers de Mongo están
sistemas completamente con Sharding

584
00:29:56,990 --> 00:30:01,740
con enrutadores mongos y múltiples
"shards" y conjuntos de réplicas

585
00:30:01,740 --> 00:30:03,180
en cada "shard".

586
00:30:03,180 --> 00:30:06,755
Pero sólo para el flujo,
no consideraré esos detalles.

587
00:30:06,755 --> 00:30:09,320

588
00:30:09,320 --> 00:30:14,380
Después que tenemos el registro
del lugar, básicamente tenemos

589
00:30:14,380 --> 00:30:19,480
todo lo que necesitamos para
registrar el "check-in".

590
00:30:19,480 --> 00:30:21,730
Así que eso es lo que hacemos.

591
00:30:21,730 --> 00:30:25,950
En este punto, podemos crear un
nuevo registro de "check-in".

592
00:30:25,950 --> 00:30:28,630

593
00:30:28,630 --> 00:30:37,550
Podemos crear un registro,
y almacenamos aquel

594
00:30:37,550 --> 00:30:40,580
"check-in" sobre Mongo.

595
00:30:40,580 --> 00:30:42,675
Así que hacemos una
operación de inserción.

596
00:30:42,675 --> 00:30:52,440

597
00:30:52,440 --> 00:30:57,590
Y lo hacemos con un
"WriteConcern" igual a "safe".

598
00:30:57,590 --> 00:30:58,710
Esta otra cosa--

599
00:30:58,710 --> 00:31:00,580
bueno esta es la primera escritura
que hiciste, las otras son

600
00:31:00,580 --> 00:31:01,450
sólo lecturas.

601
00:31:01,450 --> 00:31:04,970
Correcto, "WriteConcern"
igual a "safe", ¿correcto?

602
00:31:04,970 --> 00:31:07,743
En este punto, hemos almacenado
el "check-in", pero necesitamos

603
00:31:07,743 --> 00:31:09,930
hacer mucho más trabajo.

604
00:31:09,930 --> 00:31:15,550
Una cosa que hacemos
es calcular las

605
00:31:15,550 --> 00:31:16,770
recompensas en tu "check-in".

606
00:31:16,770 --> 00:31:18,760
Si has hecho "check-in"
en Foursquare, sabes que

607
00:31:18,760 --> 00:31:21,430
a veces obtienes una medalla
por hacer un "check-in".

608
00:31:21,430 --> 00:31:24,500
Podrías conseguir puntos, te
daremos información acerca de

609
00:31:24,500 --> 00:31:29,290
cuánto tiempo hay desde la última
vez que has estado en un lugar,

610
00:31:29,290 --> 00:31:32,200
cuántas millas hay desde
tu último "check-in".

611
00:31:32,200 --> 00:31:34,380
Para hacer eso, necesitas
mucha más información.

612
00:31:34,380 --> 00:31:36,980

613
00:31:36,980 --> 00:31:41,700
Lo único que necesitamos es
en realidad todo tu historial

614
00:31:41,700 --> 00:31:43,920
de "check-ins" hasta el momento.

615
00:31:43,920 --> 00:31:48,770
Para calcular determinadas recompensas,
medallas, necesitamos saber cuántas

616
00:31:48,770 --> 00:31:52,920
veces has estado en este
lugar en particular o

617
00:31:52,920 --> 00:31:56,900
en este tipo de lugar antes.

618
00:31:56,900 --> 00:32:00,000
Así que haremos una consulta aquí.

619
00:32:00,000 --> 00:32:02,780
No hay resultado real aquí,
pero haremos una consulta

620
00:32:02,780 --> 00:32:06,450
adicional para obtener tu
historial de "check-ins".

621
00:32:06,450 --> 00:32:12,980
Y lo que es esto, es una consulta
en el identificador de usuario contra

622
00:32:12,980 --> 00:32:14,785
la colección de "check-ins".

623
00:32:14,785 --> 00:32:18,370
La forma en que la colección de
"check-ins" funciona es que tenemos

624
00:32:18,370 --> 00:32:21,580
un documento por "check-in",
y luego hay un identificador

625
00:32:21,580 --> 00:32:24,640
de usuario en cada documento.

626
00:32:24,640 --> 00:32:28,110
Tenemos un índice en el identificador
de usuario, y la colección es en realidad

627
00:32:28,110 --> 00:32:29,970
con Sharding por este identificador.

628
00:32:29,970 --> 00:32:32,910
Haremos una consulta contra el
identificador de usuario, obtendremos

629
00:32:32,910 --> 00:32:34,575
múltiples "check-ins".

630
00:32:34,575 --> 00:32:37,120

631
00:32:37,120 --> 00:32:42,740
Una consulta en el identificador de
usuario, y luego obtenemos muchos

632
00:32:42,740 --> 00:32:43,990
documentos de "check-ins".

633
00:32:43,990 --> 00:32:49,880

634
00:32:49,880 --> 00:32:51,850
OK.

635
00:32:51,850 --> 00:32:54,180
¿Tú extraes el historial completo
si es que tiene "check-ins"?

636
00:32:54,180 --> 00:32:56,440
Sí, nosotros extraemos
el historial completo.

637
00:32:56,440 --> 00:32:58,480
Si han hecho "check-in"
miles de veces, obtenemos

638
00:32:58,480 --> 00:33:00,760
miles de documentos.

639
00:33:00,760 --> 00:33:05,300
Cada uno de nuestros documentos
es de unos 85 bytes.

640
00:33:05,300 --> 00:33:06,280
Vaya, eso es pequeño.

641
00:33:06,280 --> 00:33:08,820
Ustedes han trabajado en
mantenerlos pequeños.

642
00:33:08,820 --> 00:33:12,880
Sí, hemos trabajado mucho para
asegurarnos que las claves en

643
00:33:12,880 --> 00:33:15,500
cada documento son a
menudo un solo caracter--

644
00:33:15,500 --> 00:33:17,320
si fuera posible.

645
00:33:17,320 --> 00:33:20,680
Estamos almacenando lo
más mínimo de los datos.

646
00:33:20,680 --> 00:33:24,030
Tenemos algunos campos booleanos
allí, pero en lugar de

647
00:33:24,030 --> 00:33:30,730
poner cada booleano en su
propia clave, tenemos en

648
00:33:30,730 --> 00:33:32,270
realidad un conjunto de bits.

649
00:33:32,270 --> 00:33:36,060
Estamos almacenando un entero largo
en el documento, estamos haciendo

650
00:33:36,060 --> 00:33:39,330
un poco de aritmética
para escribir a un

651
00:33:39,330 --> 00:33:44,500
particular bit en
aquel entero largo.

652
00:33:44,500 --> 00:33:48,960
Entonces, ¿hace esto más difícil
de desarrollar, que has hecho

653
00:33:48,960 --> 00:33:52,636
todos los nombres de la claves
en un caracter en los documentos?

654
00:33:52,636 --> 00:33:55,600

655
00:33:55,600 --> 00:34:00,230
No es así, porque tenemos este
esquema estáticamente definido

656
00:34:00,230 --> 00:34:02,340
que hemos escrito
para cada documento.

657
00:34:02,340 --> 00:34:07,860
Y en el código de nuestra
aplicación, tenemos nombres muy

658
00:34:07,860 --> 00:34:09,449
convenientes para esos campos.

659
00:34:09,449 --> 00:34:10,150
Ya veo.

660
00:34:10,150 --> 00:34:12,310
Esos nombres realmente no son
vistos por los desarrolladores.

661
00:34:12,310 --> 00:34:17,360
Los desarrolladores no verán que el
campo del identificador de lugar en el

662
00:34:17,360 --> 00:34:21,962
registro "check-in" es sólo una uve (v).
Lo que ellos verán es ".venue_id"

663
00:34:21,962 --> 00:34:25,699
en el "check-in".

664
00:34:25,699 --> 00:34:28,510
Y de esa manera, las
cosas son manejables.

665
00:34:28,510 --> 00:34:32,420
Sería una situación
difícil si tenemos que

666
00:34:32,420 --> 00:34:36,530
recordar que "v" es el identificador
del lugar en algunos casos, y quizá es

667
00:34:36,530 --> 00:34:37,944
algo distinto en otros casos.

668
00:34:37,944 --> 00:34:40,909

669
00:34:40,909 --> 00:34:44,820
¿Te gustaría una funcionalidad
en MongoDB que tome cuidado

670
00:34:44,820 --> 00:34:48,590
a este tipo de mapeo para
que puedas mantenerlos cortos?

671
00:34:48,590 --> 00:34:52,199
Sí, idealmente, Mongo podría
de alguna manera comprimir

672
00:34:52,199 --> 00:34:54,730
esa información.

673
00:34:54,730 --> 00:34:57,800
Y entonces no tendríamos
que manejar eso.

674
00:34:57,800 --> 00:35:01,350
Sería conveniente si hubiera
una característica para hacer

675
00:35:01,350 --> 00:35:06,340
eso, pero lo están haciendo
ustedes, básicamente.

676
00:35:06,340 --> 00:35:07,040
Correcto.

677
00:35:07,040 --> 00:35:07,900
Sí.

678
00:35:07,900 --> 00:35:10,580
Pienso que hay un margen
de mejora allí, porque

679
00:35:10,580 --> 00:35:15,860
incluso estas claves de una sola letra
pueden estar duplicados, en nuestro caso,

680
00:35:15,860 --> 00:35:18,150
unos mil millones de veces.

681
00:35:18,150 --> 00:35:24,650
Así que tendrías unos cuantos gigabytes
de datos sólo para almacenar cada

682
00:35:24,650 --> 00:35:26,430
caracter en el nombre de la clave.

683
00:35:26,430 --> 00:35:32,310
Probablemente necesitas algún
delimitador, porque el esquema

684
00:35:32,310 --> 00:35:33,560
puede ser distinto
en cada documento.

685
00:35:33,560 --> 00:35:36,190

686
00:35:36,190 --> 00:35:38,780
Es un problema interesante.

687
00:35:38,780 --> 00:35:43,670
Sí, pienso que es uno que está
en el futuro para solucionar, y

688
00:35:43,670 --> 00:35:45,960
hay posibles soluciones allí.

689
00:35:45,960 --> 00:35:50,810
Pero es de esperar una futura
versión de Mongo que la tenga.

690
00:35:50,810 --> 00:35:55,340
Y no es usualmente un problema
hasta que se llega a

691
00:35:55,340 --> 00:35:59,690
los cientos de millones
o billones de documentos.

692
00:35:59,690 --> 00:36:03,940
Para alguien que acaba de
iniciar con Mongo, si tu

693
00:36:03,940 --> 00:36:07,570
librería no soporta cortos alias
para los nombres de las claves para

694
00:36:07,570 --> 00:36:10,770
nombres de claves extensos, es
probablemente mejor quedarse con

695
00:36:10,770 --> 00:36:13,090
un nombre legible.

696
00:36:13,090 --> 00:36:15,800
Por lo menos en el tipo
de escalabilidad en el

697
00:36:15,800 --> 00:36:18,710
que vas a ir creciendo.

698
00:36:18,710 --> 00:36:22,980
Sí, creo que uno de los
beneficios de MongoDB es la

699
00:36:22,980 --> 00:36:25,370
la legibilidad de los
datos al extraerlos.

700
00:36:25,370 --> 00:36:28,400

701
00:36:28,400 --> 00:36:32,490
Es un poco doloroso
tener que traducirlos

702
00:36:32,490 --> 00:36:33,620
para que veas el documento.

703
00:36:33,620 --> 00:36:37,030
Si estás haciendo alguna
depuración o inspección,

704
00:36:37,030 --> 00:36:39,560
es casi ofuscado.

705
00:36:39,560 --> 00:36:42,970
Sí, tenemos que ser disciplinados
en usar nuestras propias

706
00:36:42,970 --> 00:36:46,980
herramientas para hacer
investigaciones porque si ves en

707
00:36:46,980 --> 00:36:49,010
un documento de "check-in"--

708
00:36:49,010 --> 00:36:50,630
sólo los datos para Mongo--

709
00:36:50,630 --> 00:36:54,330
si usas la consola y
extraes un documento, tienes

710
00:36:54,330 --> 00:36:56,770
este tipo de nombres
ambiguos para las claves.

711
00:36:56,770 --> 00:36:59,860
A menudo es bastante obvio,
pero también tenemos

712
00:36:59,860 --> 00:37:03,800
este "flag", que es un entero largo,
que es un conjunto de bit, que ningún

713
00:37:03,800 --> 00:37:07,630
humano que conozca pueda
interpretar por ellos mismos.

714
00:37:07,630 --> 00:37:11,610
Por lo que se necesita
un equipo para eso.

715
00:37:11,610 --> 00:37:14,100
Usualmente no usamos
la consola de Mongo

716
00:37:14,100 --> 00:37:15,510
para sacar el documento.

717
00:37:15,510 --> 00:37:18,900
Lo hacemos con una consola de Scala
y usamos nuestro propio código de la

718
00:37:18,900 --> 00:37:21,150
aplicación para sacar un
documento si deseamos

719
00:37:21,150 --> 00:37:23,296
inspeccionarlo manualmente.

720
00:37:23,296 --> 00:37:27,540
Si tuvieras que hacerlo de nuevo,
¿Usarías Scala otra vez?

721
00:37:27,540 --> 00:37:32,980
Sí, pienso que Scala ha sido realmente
genial para la productividad

722
00:37:32,980 --> 00:37:35,590
de los desarrolladores.

723
00:37:35,590 --> 00:37:38,370
Es algo que pienso que muchos
desarrolladores se emocionan al

724
00:37:38,370 --> 00:37:42,610
usarlo, porque combina muchos
beneficios que obtienes de un

725
00:37:42,610 --> 00:37:44,780
lenguaje estáticamente tipado--

726
00:37:44,780 --> 00:37:47,270
todos los beneficios que obtienes
de un lenguaje estáticamente tipado--

727
00:37:47,270 --> 00:37:51,740
con algo de la flexibilidad
que tendrías en un lenguaje

728
00:37:51,740 --> 00:37:54,150
como Python o Ruby.

729
00:37:54,150 --> 00:37:57,930

730
00:37:57,930 --> 00:38:00,700
Creo que la característica más
importante es que lleva esa

731
00:38:00,700 --> 00:38:01,905
flexibilidad--

732
00:38:01,905 --> 00:38:04,860
ese tipo de estilo flexible
de lenguaje dinámico--

733
00:38:04,860 --> 00:38:10,050
es la capacidad de
crear cierres en

734
00:38:10,050 --> 00:38:12,230
línea con tu código.

735
00:38:12,230 --> 00:38:16,460
Un ejemplo de ello es si
tienes, digamos, una lista de

736
00:38:16,460 --> 00:38:21,540
"check-ins" y deseas convertir
en una lista de identificadores

737
00:38:21,540 --> 00:38:24,855
de lugares, porque esa es la
entrada para otra función.

738
00:38:24,855 --> 00:38:27,490

739
00:38:27,490 --> 00:38:29,540
En Java, lo que
tendría que hacer es--

740
00:38:29,540 --> 00:38:33,370
crearías un nuevo ArrayList,
y luego escribirías un bucle

741
00:38:33,370 --> 00:38:38,310
"for", y luego en el cuerpo
del bucle "for", añadirías

742
00:38:38,310 --> 00:38:41,750
"check-in.id" a esa lista.

743
00:38:41,750 --> 00:38:46,150
Por lo que tendrías como
cuatro líneas para hacer

744
00:38:46,150 --> 00:38:49,170
esa operación bastante básica.

745
00:38:49,170 --> 00:38:53,160
Quizá hay una oportunidad y
por consiguiente un error,

746
00:38:53,160 --> 00:38:57,800
obtener un error si iniciaste
tu bucle "for" en el

747
00:38:57,800 --> 00:39:04,610
índice equivocado o pones el
operador de comparación equivocado,

748
00:39:04,610 --> 00:39:06,200
o algo como eso.

749
00:39:06,200 --> 00:39:10,640
En Scala, en lugar de tener
que escribir estas funciones

750
00:39:10,640 --> 00:39:15,920
externas con bucles, las
colecciones tienen por defecto

751
00:39:15,920 --> 00:39:18,670
métodos de transformación
y métodos de iteración.

752
00:39:18,670 --> 00:39:24,380
Una colección tendrá un
método ".map" en ella que

753
00:39:24,380 --> 00:39:28,430
toma una función que convierte
cada elemento en la colección a

754
00:39:28,430 --> 00:39:29,920
otra cosa.

755
00:39:29,920 --> 00:39:33,536
El código converte una lista
de "check-ins" en una lista de

756
00:39:33,536 --> 00:39:37,990
identificadores básicamente se
parece como un "check-in.map".

757
00:39:37,990 --> 00:39:41,800
Y entonces una función "inline",
que en Scala podría ser sólo

758
00:39:41,800 --> 00:39:46,010
tan simple como "_.venue_id".

759
00:39:46,010 --> 00:39:49,060
Y luego en esa única
línea tendría esa

760
00:39:49,060 --> 00:39:50,660
transformación.

761
00:39:50,660 --> 00:39:53,190
Creo que se puede hacer eso
en muchos otros lenguajes

762
00:39:53,190 --> 00:39:57,840
como Python y Ruby, pero entonces
no tendríamos los beneficios de la

763
00:39:57,840 --> 00:39:58,860
compilación estática.

764
00:39:58,860 --> 00:40:01,860
No puedes obtener muchas de las
otras funcionalidades que nos hace

765
00:40:01,860 --> 00:40:06,940
productivos como comprobar estáticamente
que nuestra sintaxis de consulta de Mongo

766
00:40:06,940 --> 00:40:17,030
en realidad cederá una consulta
sensible de Mongo, porque la

767
00:40:17,030 --> 00:40:22,250
manera en que creamos
consultas es mediante la

768
00:40:22,250 --> 00:40:25,760
definición estática de
campos en nuestro esquema.

769
00:40:25,760 --> 00:40:28,030
Pero, esto se ejecuta en la JVM.

770
00:40:28,030 --> 00:40:29,040
Sí, esto se ejecuta en la JVM.

771
00:40:29,040 --> 00:40:31,960
Es un lenguaje
ejecutado dinámicamente.

772
00:40:31,960 --> 00:40:33,720
No.

773
00:40:33,720 --> 00:40:39,040
Es en realidad sólo una
sintaxís que se compila

774
00:40:39,040 --> 00:40:41,390
en bytecode de Java.

775
00:40:41,390 --> 00:40:43,630
En el momento que tu aplicación
está ejecutándose, la JVM

776
00:40:43,630 --> 00:40:46,680
no sabe en realidad que
está ejecutando Scala.

777
00:40:46,680 --> 00:40:49,930
Está sólo ejecutando
bytecode de Java.

778
00:40:49,930 --> 00:40:52,420
Es la combinación de este
compilador que toma un tipo

779
00:40:52,420 --> 00:40:56,280
distinto de sintaxis y
lo convierte en bytecode

780
00:40:56,280 --> 00:40:58,630
y una librería.

781
00:40:58,630 --> 00:40:59,880
Muy bien.

782
00:40:59,880 --> 00:41:01,750

783
00:41:01,750 --> 00:41:06,160
Este punto en que obtienes
todos los "check-ins" anteriores,

784
00:41:06,160 --> 00:41:08,300
¿qué ocurre después?

785
00:41:08,300 --> 00:41:11,260
Por aquí-- voy a aclarar
un poco esto-- pero

786
00:41:11,260 --> 00:41:16,250
calculamos cosas como qué
medallas pueden haber ganado,

787
00:41:16,250 --> 00:41:19,480
qué puntos han alcanzado,
e información básica,

788
00:41:19,480 --> 00:41:23,250
como las veces de los últimos
"check-ins", la última vez

789
00:41:23,250 --> 00:41:25,540
que estuvieron ahí, quizá
el número de millas que han

790
00:41:25,540 --> 00:41:28,580
viajado desde su
anterior "check-in".

791
00:41:28,580 --> 00:41:32,150
Voy a aclarar esto,
pero básicamente estamos

792
00:41:32,150 --> 00:41:36,960
calculando recompensas aquí.

793
00:41:36,960 --> 00:41:41,030

794
00:41:41,030 --> 00:41:44,210
La salida de estas recompensas
podrían ser información que

795
00:41:44,210 --> 00:41:46,360
almacenamos de nuevo en Mongo.

796
00:41:46,360 --> 00:41:50,320
Para cada "check-in" donde
has calificado algunos puntos,

797
00:41:50,320 --> 00:41:55,440
estamos escribiendo un documento
de calificación de regreso en Mongo.

798
00:41:55,440 --> 00:41:57,970

799
00:41:57,970 --> 00:42:01,980
Si ganas una medalla, escribiremos
un registro de eso de regreso

800
00:42:01,980 --> 00:42:04,170
en Mongo.

801
00:42:04,170 --> 00:42:08,380
Podríamos hacer algunas
escrituras más aquí.

802
00:42:08,380 --> 00:42:14,690
Pero en este punto, tenemos
toda la información básica para

803
00:42:14,690 --> 00:42:18,260
retornar un resultado
de regreso al usuario.

804
00:42:18,260 --> 00:42:20,510
Así ellos hacen "check-in",
ha sido exitoso, hemos

805
00:42:20,510 --> 00:42:22,390
calculado sus recompensas.

806
00:42:22,390 --> 00:42:27,750
Ahora retornamos un resultado
al usuario y básicamente tenemos

807
00:42:27,750 --> 00:42:29,730
toda esa información que
necesitamos para hacer eso.

808
00:42:29,730 --> 00:42:35,445
Retornaremos el "check-in"--

809
00:42:35,445 --> 00:42:38,430
el identificador de su "check-in".

810
00:42:38,430 --> 00:42:41,170
Y lo más importante a
realizar aquí, es que cuando

811
00:42:41,170 --> 00:42:43,220
insertamos este "check-in",
en realidad creamos

812
00:42:43,220 --> 00:42:45,835
el ObjectId--

813
00:42:45,835 --> 00:42:49,810
el identificador único para ese
"check-in"-- en el lado del cliente.

814
00:42:49,810 --> 00:42:51,185
Entonces no lo hacemos--

815
00:42:51,185 --> 00:42:54,170
Algo así como lo que hacemos
con el ObjectId de BSON al menos.

816
00:42:54,170 --> 00:42:55,875
Bueno son ObjectIds de BSON.

817
00:42:55,875 --> 00:42:56,280
Oh, ¿Lo son?

818
00:42:56,280 --> 00:42:57,830
Sí.

819
00:42:57,830 --> 00:43:01,280
El ObjectId para el "check-in"
se crea en el lado del cliente,

820
00:43:01,280 --> 00:43:05,600
sabemos que se hace antes que
vaya hacia la base de datos.

821
00:43:05,600 --> 00:43:08,720
Tenemos este identificador de
"check-in", tenemos el lugar en

822
00:43:08,720 --> 00:43:13,140
el que están, tenemos el resultado
del cálculo de recompensas, y

823
00:43:13,140 --> 00:43:16,180
en este punto, retornamos
un resultado al usuario.

824
00:43:16,180 --> 00:43:18,950

825
00:43:18,950 --> 00:43:22,270
Esta es una versión
extremádamente simplificada de

826
00:43:22,270 --> 00:43:24,080
lo que en realidad
estamos haciendo.

827
00:43:24,080 --> 00:43:30,400
Puedo decirte que ahí quizá
describo seis o siete operaciones

828
00:43:30,400 --> 00:43:37,270
con Mongo, pero en promedio
en realidad hacemos unas 40

829
00:43:37,270 --> 00:43:39,630
o 50 operaciones con Mongo.

830
00:43:39,630 --> 00:43:41,380
¿Tienen--

831
00:43:41,380 --> 00:43:43,490
tienen caché en Mongo
con memcached o algo?

832
00:43:43,490 --> 00:43:46,300
¿O ejecutan directamente en él?

833
00:43:46,300 --> 00:43:46,700
No.

834
00:43:46,700 --> 00:43:48,790
Consultamos directamente
hacia Mongo.

835
00:43:48,790 --> 00:43:51,130
¿Y son "stateless" tus
servidores de aplicaciones?

836
00:43:51,130 --> 00:43:51,930
Como--

837
00:43:51,930 --> 00:43:53,540
Estoy seguro que tienes
balanceo de carga en tus

838
00:43:53,540 --> 00:43:55,000
servidores de aplicaciones,
¿correcto?

839
00:43:55,000 --> 00:43:55,420
Sí.

840
00:43:55,420 --> 00:43:59,690
Si bloqueo un servidor
de aplicación durante una

841
00:43:59,690 --> 00:44:05,070
sesión, ¿pueden mis solicitudes ir
hacia estos servidores de aplicación

842
00:44:05,070 --> 00:44:08,050
en un período de unos microsegundos,
y no ser de importancia porque

843
00:44:08,050 --> 00:44:08,920
ellos son "stateless"?

844
00:44:08,920 --> 00:44:09,620
¿Cómo funciona eso?

845
00:44:09,620 --> 00:44:11,010
Sí, exacto.

846
00:44:11,010 --> 00:44:12,720
Esos servidores de aplicaciones--

847
00:44:12,720 --> 00:44:15,200
los servidores que manejan
nuestras solicitudes de API--

848
00:44:15,200 --> 00:44:17,896
que son solicitudes de los
dispositivos como iPhones,

849
00:44:17,896 --> 00:44:21,590
Blackberrys, Androids,
son "stateless".

850
00:44:21,590 --> 00:44:23,250
Y tenemos toneladas de esos.

851
00:44:23,250 --> 00:44:28,110

852
00:44:28,110 --> 00:44:30,810
Publicarás un "check-in" a
nosotros y obtienes un resultado.

853
00:44:30,810 --> 00:44:33,980
Y podrías ir al servidor de
aplicaciones uno, la siguiente

854
00:44:33,980 --> 00:44:35,980
vez que haces una solicitud hacia
nosotros, eso irá hacia un

855
00:44:35,980 --> 00:44:37,360
servidores de aplicaciones distinto.

856
00:44:37,360 --> 00:44:40,290
Y hay una razón para un
estado en ser almacenado.

857
00:44:40,290 --> 00:44:40,830

858
00:44:40,830 --> 00:44:41,630
¿Hay un estado de sesión?

859
00:44:41,630 --> 00:44:43,860
¿Tienes una colección para los
estados de sesión para que esos

860
00:44:43,860 --> 00:44:48,266
servidores de aplicaciones puedan
ir de solicitud a solicitud?

861
00:44:48,266 --> 00:44:48,640
No.

862
00:44:48,640 --> 00:44:51,540
En lo que se refiere al
API, todos los estados de

863
00:44:51,540 --> 00:44:55,520
sesión serían manejados
por la aplicación cliente.

864
00:44:55,520 --> 00:44:58,250
Si ésta es la aplicación
iPhone, está manteniendo

865
00:44:58,250 --> 00:44:59,310
lo que va a ser tu
propio dispositivo.

866
00:44:59,310 --> 00:45:00,560
Sabe donde estás en
el mismo proceso.

867
00:45:00,560 --> 00:45:03,302

868
00:45:03,302 --> 00:45:03,763
OK.

869
00:45:03,763 --> 00:45:05,150
Muy bien.

870
00:45:05,150 --> 00:45:05,750
Gracias.

871
00:45:05,750 --> 00:45:07,000
Claro.