1
00:00:00,000 --> 00:00:00,090

2
00:00:00,090 --> 00:00:02,160
I want to show you how to
use regular expressions

3
00:00:02,160 --> 00:00:04,287
inside MongoDB with Python.

4
00:00:04,287 --> 00:00:06,495
But before I do that, we
really need some better data

5
00:00:06,495 --> 00:00:07,720
to play with.

6
00:00:07,720 --> 00:00:11,300
And so to do that, I'm going to
pull in some data from Reddit.

7
00:00:11,300 --> 00:00:13,570
And I think this illustrates
one of the real strengths

8
00:00:13,570 --> 00:00:18,040
of MongoDB, which is how easy
it is to ingest data, especially

9
00:00:18,040 --> 00:00:19,840
data that you don't
quite understand

10
00:00:19,840 --> 00:00:22,390
the structure of before
you start playing with it.

11
00:00:22,390 --> 00:00:24,810
So this is Reddit's home
page-- Reddit's technology

12
00:00:24,810 --> 00:00:26,280
homepage from today.

13
00:00:26,280 --> 00:00:29,620
And we're going to pull in
these stories to MongoDB.

14
00:00:29,620 --> 00:00:32,299
Let's see how we would
start thinking about that.

15
00:00:32,299 --> 00:00:35,830
So first of all, Reddit has
this nice feature where if you

16
00:00:35,830 --> 00:00:40,676
append .JSON to your URL-- you
see I just put .JSON at the end

17
00:00:40,676 --> 00:00:44,660
of that URL-- then it's going
to show you a .JSON version

18
00:00:44,660 --> 00:00:46,670
of their home page.

19
00:00:46,670 --> 00:00:48,080
And this is pretty overwhelming.

20
00:00:48,080 --> 00:00:50,252
And the data looks
pretty complicated.

21
00:00:50,252 --> 00:00:52,460
So let's see if we can sift
through this a little bit

22
00:00:52,460 --> 00:00:54,610
to figure out what
the structure is.

23
00:00:54,610 --> 00:00:57,570
So to do that, I'm going
to go into the terminal.

24
00:00:57,570 --> 00:01:00,831
And I'm going to curl this URL.

25
00:01:00,831 --> 00:01:02,706
So it was www.reddit.com/r
/technology/.json.

26
00:01:02,706 --> 00:01:08,970

27
00:01:08,970 --> 00:01:13,931
And I'm going to put that into
a file called reddit.json.

28
00:01:13,931 --> 00:01:14,430
Alright.

29
00:01:14,430 --> 00:01:15,650
So I did that.

30
00:01:15,650 --> 00:01:18,680
And now I have that file.

31
00:01:18,680 --> 00:01:20,380
And it's still
pretty complicated.

32
00:01:20,380 --> 00:01:22,080
So how can I make it better?

33
00:01:22,080 --> 00:01:25,010
Well, it turns out there's
a built-in system in Python

34
00:01:25,010 --> 00:01:26,750
for dealing with JSON.

35
00:01:26,750 --> 00:01:31,590
So I'm going to cat that file,
reddit.json, and redirect it

36
00:01:31,590 --> 00:01:36,640
to Python, and to a
module called json.tool.

37
00:01:36,640 --> 00:01:39,650
And this minus m runs
the module as a script.

38
00:01:39,650 --> 00:01:44,020
And then I'm going to
just send that to more,

39
00:01:44,020 --> 00:01:45,740
and take a look at that file.

40
00:01:45,740 --> 00:01:46,240
Alright.

41
00:01:46,240 --> 00:01:47,640
So that's much better.

42
00:01:47,640 --> 00:01:49,310
So with that little
command I was

43
00:01:49,310 --> 00:01:51,290
able to pretty
print this JSON file

44
00:01:51,290 --> 00:01:53,080
and start inspecting
the structure.

45
00:01:53,080 --> 00:01:55,120
And I did this a little
bit before I recorded.

46
00:01:55,120 --> 00:01:57,220
And it looks like
what we have here

47
00:01:57,220 --> 00:02:02,100
is the JSON document with data,
with a subkey called children.

48
00:02:02,100 --> 00:02:04,060
And in there is an array.

49
00:02:04,060 --> 00:02:05,950
And then these
documents that come

50
00:02:05,950 --> 00:02:09,400
after all seem to be
stories, where the story is

51
00:02:09,400 --> 00:02:11,400
under the data key.

52
00:02:11,400 --> 00:02:15,260
So you can see here we have
a story, the permalink,

53
00:02:15,260 --> 00:02:17,880
and the title, I think, is
the thing that's interesting.

54
00:02:17,880 --> 00:02:20,550
Japanese scientists have
succeed in transmitting energy.

55
00:02:20,550 --> 00:02:22,450
This was the first story
you saw on the page.

56
00:02:22,450 --> 00:02:24,640
And then here's another story.

57
00:02:24,640 --> 00:02:26,072
Et cetera, et cetera, et cetera.

58
00:02:26,072 --> 00:02:28,030
So I can figure out what
the structure is here.

59
00:02:28,030 --> 00:02:30,160
And I should be able use
that to pull data in.

60
00:02:30,160 --> 00:02:32,450
So let me show you a
program to do that.

61
00:02:32,450 --> 00:02:35,100
Here's the program that's going
to read this data directly

62
00:02:35,100 --> 00:02:36,990
from Reddit, and
put it into MongoDB.

63
00:02:36,990 --> 00:02:38,990
It uses some modules
that we're not

64
00:02:38,990 --> 00:02:41,340
going to use very often, or
even at all in this class.

65
00:02:41,340 --> 00:02:43,210
So you don't need to
really understand them.

66
00:02:43,210 --> 00:02:45,340
But urllib2 is the one.

67
00:02:45,340 --> 00:02:47,470
And the JSON one as well.

68
00:02:47,470 --> 00:02:50,590
And the ulrlib2 is going to let
us do a web request to Reddit.

69
00:02:50,590 --> 00:02:53,190
And the JSON one is
going to parse the JSON.

70
00:02:53,190 --> 00:02:55,850
So we make a connection to
local host from MongoDB.

71
00:02:55,850 --> 00:02:57,250
Some place to put the data.

72
00:02:57,250 --> 00:03:00,070
Make a connection to the
Reddit database inside MongoDB,

73
00:03:00,070 --> 00:03:01,777
which of course, we
haven't used before.

74
00:03:01,777 --> 00:03:03,860
But it will be auto-created
as soon as we put data

75
00:03:03,860 --> 00:03:05,000
in the collection.

76
00:03:05,000 --> 00:03:07,234
And then a stories collection.

77
00:03:07,234 --> 00:03:08,650
I've run this
multiple times, so I

78
00:03:08,650 --> 00:03:10,730
needed to drop the stories
collection beforehand

79
00:03:10,730 --> 00:03:12,146
to make sure
everything was empty.

80
00:03:12,146 --> 00:03:13,590
So I did that here.

81
00:03:13,590 --> 00:03:16,310
And then I found
the Reddit page,

82
00:03:16,310 --> 00:03:17,750
which is the one
we showed before,

83
00:03:17,750 --> 00:03:21,000
which is
reddit.com/r/technology/.json.

84
00:03:21,000 --> 00:03:25,330
And I opened it using urllib2
to get a handle to that page.

85
00:03:25,330 --> 00:03:27,490
And then I need a parsed
version of this page.

86
00:03:27,490 --> 00:03:31,220
So I call the JSON module that
I imported, and I load it up,

87
00:03:31,220 --> 00:03:32,447
and I read the whole thing.

88
00:03:32,447 --> 00:03:34,405
And that's going to create
a bunch of documents

89
00:03:34,405 --> 00:03:35,995
that I can iterate through.

90
00:03:35,995 --> 00:03:38,120
Now we already know what
the structure of this page

91
00:03:38,120 --> 00:03:39,870
is, because we pulled
the URL and read it.

92
00:03:39,870 --> 00:03:40,910
We put into a text file.

93
00:03:40,910 --> 00:03:43,690
And we put it through a
version of the JSON module

94
00:03:43,690 --> 00:03:45,390
so we could see it.

95
00:03:45,390 --> 00:03:47,070
And so we know what's
really interesting

96
00:03:47,070 --> 00:03:50,250
in each of these documents
is we need to look at,

97
00:03:50,250 --> 00:03:52,970
in the parsed version, really
it's just the first document

98
00:03:52,970 --> 00:03:54,040
that we need.

99
00:03:54,040 --> 00:03:57,100
We just need whatever
is in data children.

100
00:03:57,100 --> 00:04:00,130
So parsed, data, children.

101
00:04:00,130 --> 00:04:03,780
That field itself,
the value is an array,

102
00:04:03,780 --> 00:04:05,170
which is each of the stories.

103
00:04:05,170 --> 00:04:08,850
And I learned that by just
inspecting by hand what

104
00:04:08,850 --> 00:04:11,090
was brought back from Reddit.

105
00:04:11,090 --> 00:04:11,790
OK.

106
00:04:11,790 --> 00:04:14,123
So once I have each of the
stories in the JSON document,

107
00:04:14,123 --> 00:04:15,120
now it's really simple.

108
00:04:15,120 --> 00:04:17,890
I just call insert
one on each one.

109
00:04:17,890 --> 00:04:18,870
And that's it.

110
00:04:18,870 --> 00:04:21,529
And I look inside each one
and pull the data element out,

111
00:04:21,529 --> 00:04:23,900
because I noticed that there
was sort of an extra level

112
00:04:23,900 --> 00:04:25,650
hierarchy there that
I don't care about.

113
00:04:25,650 --> 00:04:28,940
If you go back to the original
file, you'll see that.

114
00:04:28,940 --> 00:04:31,950
So let's run this
and see what we get.

115
00:04:31,950 --> 00:04:35,830
So we're going to
python read_reddit.py.

116
00:04:35,830 --> 00:04:38,490
And if I do that, it runs,
runs without incident.

117
00:04:38,490 --> 00:04:41,910
And now we need to look
inside the database.

118
00:04:41,910 --> 00:04:43,880
So we're going to start Mongo.

119
00:04:43,880 --> 00:04:46,010
We're going to use
the Reddit database.

120
00:04:46,010 --> 00:04:50,710
And then we are going
to look at db.stories.

121
00:04:50,710 --> 00:04:52,530
We'll do a find one on that.

122
00:04:52,530 --> 00:04:53,230
Alright.

123
00:04:53,230 --> 00:04:55,460
So we did a find one on this.

124
00:04:55,460 --> 00:04:58,150
And the first document
in the stories collection

125
00:04:58,150 --> 00:05:04,320
inside MongoDB now is the story
on Japanese scientists finding

126
00:05:04,320 --> 00:05:07,010
a wireless way to
transmit energy.

127
00:05:07,010 --> 00:05:08,140
So that's great.

128
00:05:08,140 --> 00:05:09,640
That's exactly what we wanted.

129
00:05:09,640 --> 00:05:13,310
And if we find a whole bunch
of documents, which we can do,

130
00:05:13,310 --> 00:05:15,600
then it's not going
to be formatted.

131
00:05:15,600 --> 00:05:17,020
I'll do it pretty.

132
00:05:17,020 --> 00:05:17,590
There we go.

133
00:05:17,590 --> 00:05:19,200
Now we have multiple stories.

134
00:05:19,200 --> 00:05:20,700
Each one its own document.

135
00:05:20,700 --> 00:05:21,460
Perfect.

136
00:05:21,460 --> 00:05:24,430
Now we finally have some
data that we can search,

137
00:05:24,430 --> 00:05:27,140
and we can use for the
subsequent lessons.